{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN (binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEPS\n",
    "\n",
    "1. General information about the data\n",
    "    - `data.info()`\n",
    "    - `pd.set_option('display.max_columns',30)` --> ... 으로 생략되는 columns 들을 보여줌 \n",
    "    - `pd.set_option('display.max_rows',30)` --> 생략되는 row도 지정 숫자만큼 (30) 보여줌\n",
    "    - **what if numerical type is saved as text?**\n",
    "        - `pd.to_numeric(data['name of column'])`\n",
    "        - **if still showing error?** --> go to the specific row\n",
    "            - identify the problem\n",
    "            - exaample) \"_\" is inputed while you want to have \"\"\n",
    "            - `data['name of column'] =  data['name of column'].replace(\"_\",\"\")`\n",
    "2. Descriptive Statistics of the data\n",
    "    - `data.describe()`\n",
    "    - `sns.displot(data['name of column'])`\n",
    "3. Missing Values\n",
    "    - Check missing value\n",
    "    - Fill them up \n",
    "    - Details from LogisticRegression File\n",
    "4. Scaling\n",
    "    - **가능하면 종속변수 (Dependent Variable)은 Scaling 에서 제외**\n",
    "    - `from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler`\n",
    "    - Standard Scale\n",
    "        - `standard = StandardScaler()`\n",
    "        - `standard.fit(...)`\n",
    "        - `Scaled_st = standard.transform(...)`\n",
    "        - > 가장 기본적인 통계학적 스케일\n",
    "    - MinMax Scale\n",
    "        - `mixmax = MinMaxScaler()`\n",
    "        - `mixmax.fit(....)`\n",
    "        - `scaled_minmax = minmax.transform(...)`\n",
    "        - > 자기 각자만의 데이터에서의 분포를 갖음. **가장 무난함**. 왜냐하면, 데이터 분포의 특성을 왜곡하지않음. 좀더 정규화해서 볼 필요가 있다, 그러면 Standard or Robust (outlier 의 유무 및 영향력 조절)\n",
    "    - Robust Scale\n",
    "        - `rob = RobustScaler()\n",
    "        - `rob.fit(....)`\n",
    "        - `scaled_rob = rob.transform(...)`\n",
    "        - > Standard Scale에 비해서 **Outlier**의 영향을 훨씬 적게 받음, Q1,Q3등을 이용한 계산\n",
    "5. Train/Test Set Split\n",
    "    - Same\n",
    "6. Start Modeling\n",
    "    - `from sklearn.neighbors import KNeighborsClassifier`\n",
    "    - `knn = KNeighborsClassifier(n_neighbors=10)`\n",
    "    - `knn.fit(X_train, y_train)`\n",
    "    - `pred = knn.predict(X_test)`\n",
    "7. Evaluation\n",
    "    - Finding the optimal K value using for loop/list\n",
    "    - Confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Coding in hands\n",
    "\n",
    "1. get dummies\n",
    "    - `pd.get_dummies(data, columns = ['column'], drop_first = True)` --> turn the column into dummies, and drop one. \n",
    "2. Using **loop**\n",
    "    1. Put ones datatype into one place. \n",
    "        - ```\n",
    "           col_list = []\n",
    "           for i in data.columns:\n",
    "               if data[i].dtype = 'the datatype you are looking for':\n",
    "                   col_list.append(i)`\n",
    "          ```\n",
    "        -  ```\n",
    "         for i in col_list:\n",
    "             print(i, datap[i], nunique())\n",
    "        ```\n",
    "        - 첫번째에는 내가 원하는 데이타 타입을 갖고있는애들을 모두 한곳으로 모아주었고, 두번째에서는 각 variable별 unique한 value를 몇개씩 갖고있는지 나타내어줌.\n",
    "     2. `pd.get_dummies(data, columns = col_list, drop_first = True)` --> 모두 dummies로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
